{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\program files (x86)\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in d:\\program files (x86)\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in d:\\program files (x86)\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install pandas\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install nltk\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "splitter = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "file_name=\"data2.csv\"\n",
    "\n",
    "# Read File\n",
    "df=pd.read_csv(file_name)\n",
    "# df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=pd.read_csv(file_name)\n",
    "documentname_list=list(df['label_dis'])\n",
    "print(documentname_list)\n",
    "df=df.iloc[:,1:]\n",
    "columnsName=list(df.columns)\n",
    "\n",
    "# print(columnsName)\n",
    "\n",
    "documentname_list=list(documentname_list)\n",
    "\n",
    "# df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Num_of_diseases=len(df) \n",
    "Num_of_symptoms=len(columnsName)\n",
    "print(Num_of_diseases,Num_of_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inverted_document_frequency={}\n",
    "\n",
    "# inverted_document_frequency for diseases in the dataset\n",
    "for col in columnsName:\n",
    "  temp=np.count_nonzero(df[col])\n",
    "#   print(df[col])\n",
    "  inverted_document_frequency[col]=np.log(Num_of_diseases/temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# term Frequency for all diseases in dataset\n",
    "term_frequency={}\n",
    "# df.loc[0,'abdominal cramp']\n",
    "\n",
    "for i in range(Num_of_diseases):\n",
    "  for col in columnsName:\n",
    "    key=(documentname_list[i],col)\n",
    "    term_frequency[key]=df.loc[i,col]\n",
    "# term_frequency   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tf-inverted_document_frequency Score for [Document(Disease Name),Symptom name] as-key  and  \"weight of the disease word\" as-value\n",
    "term_frequency_inverted_document_frequency={}\n",
    "for i in range(Num_of_diseases):\n",
    "  for col in columnsName:\n",
    "    key=(documentname_list[i],col)\n",
    "    term_frequency_inverted_document_frequency[key]=float(inverted_document_frequency[col])*float(term_frequency[key])\n",
    "#     print(str(key)+\"=>\"+str(term_frequency_inverted_document_frequency[key]))\n",
    "term_frequency_inverted_document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_frequency-inverted_document_frequency score 2-d array for \"each symptom with disease name\"\n",
    "D_2d = np.zeros((Num_of_diseases, Num_of_symptoms),dtype='float32')\n",
    "for i in term_frequency_inverted_document_frequency:\n",
    "    sym = columnsName.index(i[1])\n",
    "    dis=documentname_list.index(i[0])\n",
    "    D_2d[dis][sym] = term_frequency_inverted_document_frequency[i]\n",
    "D_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "Y = df.iloc[:, 0:1]\n",
    "X = df.iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_dataset = list(X.columns)\n",
    "# list of all Symptoms\n",
    "symptoms_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diseases = list(set(Y['label_dis']))\n",
    "# List of all Diseases\n",
    "\n",
    "diseases.sort()\n",
    "diseases\n",
    "# len(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_symptoms = str(input(\"\\nPlease enter symptoms separated by comma(,):\\n\")).lower().split(',')\n",
    "user_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_user_symptoms=[]\n",
    "for sym in user_symptoms:\n",
    "    sym=sym.strip()\n",
    "    sym=sym.replace('-',' ')\n",
    "    sym=sym.replace(\"'\",'')\n",
    "    sym = ' '.join([lemmatizer.lemmatize(word) for word in splitter.tokenize(sym)])\n",
    "    processed_user_symptoms.append(sym)\n",
    "processed_user_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_symptoms=processed_user_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_matched = set()\n",
    "for idx, data in enumerate(symptoms_dataset):\n",
    "    data_split=data.split()\n",
    "    for user_sym in user_symptoms:\n",
    "        count=0\n",
    "        for symp in data_split:\n",
    "            if symp in user_sym.split():\n",
    "                count+=1\n",
    "        if count/len(data_split)>0.5:\n",
    "            symptoms_matched.add(data)\n",
    "symptoms_matched = list(symptoms_matched)\n",
    "symptoms_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(symptoms_matched)\n",
    "# retreive the whole set of diseases in (set_diseases) containing the symptoms in the \"symptoms_matched\"\n",
    "set_diseases = set()\n",
    "finalSymptoms = [] \n",
    "MatchedDiseases = []\n",
    "for idx in symptoms_matched:\n",
    "    \n",
    "    finalSymptoms.append(idx)\n",
    "    set_diseases.update(set(df[df[idx]==1]['label_dis']))\n",
    "\n",
    "print(\"diseaseList\")\n",
    "set_diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diseaseList List the whole Symptoms in it\n",
    "for dis in set_diseases:\n",
    "    row = df.loc[df['label_dis'] == dis].values.tolist()\n",
    "    row[0].pop(0)\n",
    "    for idx,val in enumerate(row[0]):\n",
    "        if val!=0 and symptoms_dataset[idx] not in finalSymptoms:\n",
    "            MatchedDiseases.append(symptoms_dataset[idx])\n",
    "print(\"whole set of symptoms\")\n",
    "MatchedDiseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from whole list of diseases count the occurrences and store it in a tuple\n",
    "dict_symp = dict(Counter(MatchedDiseases))\n",
    "dict_symp\n",
    "dict_symp_tup = sorted(dict_symp.items(), key=operator.itemgetter(1),reverse=True)\n",
    "print(dict_symp_tup)\n",
    "print(\"-----------------------------------------------\")\n",
    "alldis=[]\n",
    "# disease List\n",
    "for i in dict_symp_tup:\n",
    "    alldis.append(i[0])\n",
    "print(alldis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_matched=[]\n",
    "counter=0\n",
    "# print(finalSymptoms)\n",
    "\n",
    "\n",
    "# append top ten most occurring symptoms into finalSymptomstomsList\n",
    "    \n",
    "for i in dict_symp_tup:\n",
    "  if counter<10:\n",
    "    symptoms_matched.append(i[0])\n",
    "    counter+=1\n",
    "  else :\n",
    "    break\n",
    "print(symptoms_matched)\n",
    "for idx in symptoms_matched:\n",
    "    if idx not in finalSymptoms:\n",
    "            finalSymptoms.append(idx)\n",
    "finalSymptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine the input of symptoms by adding the more Symptoms to it\n",
    "input2=input(\"enter some more symptoms from printed above Symptoms:\")\n",
    "arr3=input2.split(\",\")\n",
    "for i in arr3:\n",
    "    finalSymptoms.append(i)\n",
    "finalSymptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10\n",
    "# print the top 10 documents based term_frequency_inverted_document_frequency score in between the \"query\" word and the term_frequency_inverted_document_frequency of the disease word\n",
    "def term_frequency_inverted_document_frequency_score(count, query):\n",
    "    query_weights = {}\n",
    "    for key in term_frequency_inverted_document_frequency:\n",
    "        \n",
    "        if key[1] in query:\n",
    "            try:\n",
    "                query_weights[key[0]] += term_frequency_inverted_document_frequency[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = term_frequency_inverted_document_frequency[key]\n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "  \n",
    "    l = []\n",
    "    for i in query_weights[:count]:\n",
    "        l.append(i)\n",
    "    return l\n",
    "tf_idf_scored_docs=term_frequency_inverted_document_frequency_score(count,finalSymptoms)\n",
    "print(tf_idf_scored_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Diseases Based on Tf-Idf Scoring\")\n",
    "i = 0\n",
    "tf_idf_scored_docs_index_mapping = {}\n",
    "for key, val in tf_idf_scored_docs:\n",
    "#   print(f\"{i}. Disease : {key} \\t Score : {round(score, 2)}\")\n",
    "  print( f\"{key} =======> {round(val, 2)}\")\n",
    "  tf_idf_scored_docs_index_mapping[i] = key\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_dot(a, b):\n",
    "    if np.linalg.norm(a) == 0 or np.linalg.norm(b) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        temp = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "        return temp\n",
    "    \n",
    "def gen_vector(tokens):\n",
    "    Q = np.zeros(Num_of_symptoms)\n",
    "    counter = Counter(tokens)\n",
    "    query_weights = {}\n",
    "    for token in np.unique(tokens):\n",
    "        term_frequency = counter[token]\n",
    "        try:\n",
    "          inverted_document_frequency_temp=inverted_document_frequency[token]\n",
    "        except:\n",
    "          pass\n",
    "        try:\n",
    "            ind = columnsName.index(token)\n",
    "            Q[ind] = term_frequency*inverted_document_frequency_temp\n",
    "        except:\n",
    "            pass\n",
    "    return Q  \n",
    "\n",
    "def cosine_similarity(count, query):\n",
    "    d_cosines = []\n",
    "    query_vector = gen_vector(query)\n",
    "    for d in D_2d:\n",
    "        d_cosines.append(cosine_dot(query_vector, d))\n",
    "    out = np.array(d_cosines).argsort()[-count:][::-1]\n",
    "  \n",
    "    final_display_disease={}\n",
    "    for lt in set(out):\n",
    "      final_display_disease[lt] = float(d_cosines[lt])\n",
    "    return final_display_disease\n",
    "\n",
    "cosine_similiarity_docs1=cosine_similarity(count,finalSymptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\" Disease based on Cosine Similarity \")\n",
    "\n",
    "print(cosine_similiarity_docs1)\n",
    "\n",
    "cosine_similiarity_docs1_sorted = dict(sorted(cosine_similiarity_docs1.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "print(cosine_similiarity_docs1_sorted)\n",
    "print()\n",
    "j = 0\n",
    "cosine_similiarity_docs1_index_mapping = {}\n",
    "for key in cosine_similiarity_docs1_sorted:\n",
    "  print(f\" {diseases[key]} =====> {round(cosine_similiarity_docs1_sorted[key], 2)}\")\n",
    "  cosine_similiarity_docs1_index_mapping[j] = diseases[key]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pseudo relevance feedback\n",
    "\n",
    "diseases\n",
    "dd_keys=list(cosine_similiarity_docs1_sorted.keys())\n",
    "dd=[]\n",
    "print(dd_keys)\n",
    "    \n",
    "j=0    \n",
    "for i in dd_keys:\n",
    "    if j<5:\n",
    "        dd.append(i)\n",
    "        j+=1\n",
    "print(dd)\n",
    "\n",
    "symp=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in dd:\n",
    "    for col in columnsName:\n",
    "        if(df.loc[i,col]!=0):\n",
    "         symp.append(col)\n",
    "symp=list(set(symp))\n",
    "symp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosine_similiarity_docs3=cosine_similarity(count,symp)\n",
    "\n",
    "\n",
    "# In[108]:\n",
    "\n",
    "\n",
    "print(\"Top most 10 Refined  Diseases  on Cosine Similarity \")\n",
    "print()\n",
    "print(cosine_similiarity_docs3)\n",
    "\n",
    "cosine_similiarity_docs3_sorted = dict(sorted(cosine_similiarity_docs3.items(), key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "print(cosine_similiarity_docs3_sorted)\n",
    "print()\n",
    "\n",
    "\n",
    "cosine_similiarity_docs3_index_mapping = {}\n",
    "for key in cosine_similiarity_docs3_sorted:\n",
    "  print(f\" {diseases[key]} =========> {round(cosine_similiarity_docs3_sorted[key], 2)}\")\n",
    "  cosine_similiarity_docs3_index_mapping[j] = diseases[key]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Accuracy\n",
    "# diseases\n",
    "dd_keys=list(cosine_similiarity_docs1_sorted.keys())\n",
    "dd2=[]\n",
    "print(dd_keys)\n",
    "for i in dd_keys:\n",
    "   dd2.append(diseases[i])\n",
    "# print(dd2)\n",
    "\n",
    "\n",
    "\n",
    "dd_keys=list(cosine_similiarity_docs3_sorted.keys())\n",
    "dd3=[]\n",
    "print(dd_keys)\n",
    "for i in dd_keys:\n",
    "   dd3.append(diseases[i])\n",
    "# print(dd3)\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "\n",
    "#Accuracy\n",
    "\n",
    "def common(a,b): \n",
    "    c = [value for value in a if value in b] \n",
    "    return c\n",
    "\n",
    "d=common(dd2,dd3)\n",
    "print(\"Accuracy Before and after Pseudo Relevance Feedback is :\",(len(d)/10) *100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting in graph\n",
    "diseases_lst = dd3\n",
    " \n",
    "data = list(cosine_similiarity_docs3_sorted.values())\n",
    " \n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data, labels = diseases_lst)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x = dd3\n",
    "y = list(cosine_similiarity_docs3_sorted.values())\n",
    "\n",
    "plt.barh(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Nov 21 2021, 22:02:56)  [GCC 11.2.0 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a8dfe095fce2b5e88c64a2c3ee084c8e0e0d70b23e7b95b1cfb538be294c5c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
